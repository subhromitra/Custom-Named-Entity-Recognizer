{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Custom Named Entity Recognizer</h1>\n",
    "\n",
    "Named entity recognizer's are generally trained on texts from web articles or news articles. In such cases they are not able to recognize entities from finance or medical domain. For such use cases, we need to train the NER using domain specific labelled data. \n",
    "\n",
    "If training data is large then we may train an NER from scratch. But if we don't have sufficient data then we may retrain a previously trained NER with new data.\n",
    "\n",
    "For this use case since our data is large enough to train an NER model from scratch.\n",
    "<br>\n",
    "\n",
    "<h3>Problem Description</h3>\n",
    "\n",
    "The core problem that we are trying to solve here is :- Given a text (sentence), we have to find out the different types of entities in that text, e.g - names of people, organizations, places etc. \n",
    "\n",
    "We can model it as a **many-to-many** sequence prediction problem, i.e, input is a sentence (set of tokens) & output is a set of tags describing each token.\n",
    "<br>\n",
    "\n",
    "<h3>Dataset Description :-</h3>\n",
    "\n",
    "The dataset used was extracted from GMB corpus (Groningen Meaning Bank) & can be found here :- https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus . We have nearly 48K labelled sentences.\n",
    "<br>\n",
    "\n",
    "<h3>Plan of Attack</h3>\n",
    "\n",
    "We are going to train a **Bi-LSTM model** from scratch. We are going to use the Keras library for this task, although we could also use SpaCy for performing this task also - by using an empty pipeline & including an untrained NER in that pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WepyMEJ560zc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "id": "BqwB1NCu7E9W",
    "outputId": "5ffa89ac-e518-4626-f3a4-57e9f8eed7bb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1          NaN             of   IN   O\n",
       "2          NaN  demonstrators  NNS   O\n",
       "3          NaN           have  VBP   O\n",
       "4          NaN        marched  VBN   O"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"ner_dataset.csv\", encoding='latin')#ner_dataset.csv\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qcc9JLIO9ugL",
    "outputId": "1b851966-03f2-4346-be72-fc49c02dc96f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048575, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## cHECKING NO.OF ROWS IN THE DATASET\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WaGpbu0f7NAM",
    "outputId": "1cc42967-1f9f-4502-e84e-4aae67d40b4a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NNS', 'IN', 'VBP', 'VBN', 'NNP', 'TO', 'VB', 'DT', 'NN', 'CC',\n",
       "       'JJ', '.', 'VBD', 'WP', '``', 'CD', 'PRP', 'VBZ', 'POS', 'VBG',\n",
       "       'RB', ',', 'WRB', 'PRP$', 'MD', 'WDT', 'JJR', ':', 'JJS', 'WP$',\n",
       "       'RP', 'PDT', 'NNPS', 'EX', 'RBS', 'LRB', 'RRB', '$', 'RBR', ';',\n",
       "       'UH', 'FW'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## CHECKING THE POS TAGS IN THIS DATASET\n",
    "df[\"POS\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2U3MW1fv8Fyl",
    "outputId": "5be9baaf-b0c5-47fb-f863-4ceea06c0201"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.of unique tags :-  17\n",
      "Unique tags are :-\n",
      " ['O' 'B-geo' 'B-gpe' 'B-per' 'I-geo' 'B-org' 'I-org' 'B-tim' 'B-art'\n",
      " 'I-art' 'I-per' 'I-gpe' 'I-tim' 'B-nat' 'B-eve' 'I-eve' 'I-nat']\n"
     ]
    }
   ],
   "source": [
    "## CHECKING THE UNIQUE TAGS IN THIS DATASET\n",
    "print(\"No.of unique tags :- \",len(df[\"Tag\"].unique()))\n",
    "print(\"Unique tags are :-\\n\",df[\"Tag\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Therefore no.of output classes is 17**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_cBI9gRkgfHC"
   },
   "outputs": [],
   "source": [
    "## INDEXING EACH UNIQUE TOKEN\n",
    "vocab = list(set(data[\"Word\"].values))\n",
    "idx2word = {idx:tok for  idx, tok in enumerate(vocab)}\n",
    "word2idx = {tok:idx for  idx, tok in enumerate(vocab)}\n",
    "\n",
    "## INDEXING EACH UNIQUE TAG\n",
    "tags = list(set(data[\"Tag\"].values))\n",
    "idx2tag = {idx:tok for  idx, tok in enumerate(tags)}\n",
    "tag2idx = {tok:idx for  idx, tok in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VBb05c224G9R",
    "outputId": "1e2c8cf7-ab4a-479e-8890-c617fa8b5c94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35178 17\n"
     ]
    }
   ],
   "source": [
    "## CHECKING NO.OF UNIQUE TOKENS & TAGS\n",
    "n_token, n_tags = len(vocab), len(tags)\n",
    "print(n_token, n_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "id": "CNeD92svg7XO",
    "outputId": "84f1bed0-3ab9-488d-a7e0-bdfcf6c9e83f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Word_idx</th>\n",
       "      <th>Tag_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>19018</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>28958</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>6523</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "      <td>26274</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "      <td>22699</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag  Word_idx  Tag_idx\n",
       "0  Sentence: 1      Thousands  NNS   O     19018       10\n",
       "1          NaN             of   IN   O     28958       10\n",
       "2          NaN  demonstrators  NNS   O      6523       10\n",
       "3          NaN           have  VBP   O     26274       10\n",
       "4          NaN        marched  VBN   O     22699       10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Word_idx'] = data['Word'].map(word2idx)\n",
    "data['Tag_idx'] = data['Tag'].map(tag2idx)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "id": "O4RuJzS5g_AW",
    "outputId": "008751aa-cfae-4535-8819-2cf0c1abfe5e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Word_idx</th>\n",
       "      <th>Tag_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>[Thousands, of, demonstrators, have, marched, ...</td>\n",
       "      <td>[NNS, IN, NNS, VBP, VBN, IN, NNP, TO, VB, DT, ...</td>\n",
       "      <td>[O, O, O, O, O, O, B-geo, O, O, O, O, O, B-geo...</td>\n",
       "      <td>[19018, 28958, 6523, 26274, 22699, 24439, 2842...</td>\n",
       "      <td>[10, 10, 10, 10, 10, 10, 14, 10, 10, 10, 10, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 10</td>\n",
       "      <td>[Iranian, officials, say, they, expect, to, ge...</td>\n",
       "      <td>[JJ, NNS, VBP, PRP, VBP, TO, VB, NN, TO, JJ, J...</td>\n",
       "      <td>[B-gpe, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "      <td>[13322, 22989, 12146, 19667, 9546, 28280, 3462...</td>\n",
       "      <td>[4, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 100</td>\n",
       "      <td>[Helicopter, gunships, Saturday, pounded, mili...</td>\n",
       "      <td>[NN, NNS, NNP, VBD, JJ, NNS, IN, DT, NNP, JJ, ...</td>\n",
       "      <td>[O, O, B-tim, O, O, O, O, O, B-geo, O, O, O, O...</td>\n",
       "      <td>[9218, 16783, 1307, 20430, 7430, 15039, 31013,...</td>\n",
       "      <td>[10, 10, 7, 10, 10, 10, 10, 10, 14, 10, 10, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1000</td>\n",
       "      <td>[They, left, after, a, tense, hour-long, stand...</td>\n",
       "      <td>[PRP, VBD, IN, DT, NN, JJ, NN, IN, NN, NNS, .]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[25096, 1196, 19790, 18480, 26691, 17302, 304,...</td>\n",
       "      <td>[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 10000</td>\n",
       "      <td>[U.N., relief, coordinator, Jan, Egeland, said...</td>\n",
       "      <td>[NNP, NN, NN, NNP, NNP, VBD, NNP, ,, NNP, ,, J...</td>\n",
       "      <td>[B-geo, O, O, B-per, I-per, O, B-tim, O, B-geo...</td>\n",
       "      <td>[17382, 21132, 5856, 3268, 1865, 17041, 9654, ...</td>\n",
       "      <td>[14, 10, 10, 3, 8, 10, 7, 10, 14, 10, 4, 10, 4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sentence #  ...                                            Tag_idx\n",
       "0      Sentence: 1  ...  [10, 10, 10, 10, 10, 10, 14, 10, 10, 10, 10, 1...\n",
       "1     Sentence: 10  ...  [4, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10...\n",
       "2    Sentence: 100  ...  [10, 10, 7, 10, 10, 10, 10, 10, 14, 10, 10, 10...\n",
       "3   Sentence: 1000  ...       [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
       "4  Sentence: 10000  ...  [14, 10, 10, 3, 8, 10, 7, 10, 14, 10, 4, 10, 4...\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Fill na\n",
    "data_fillna = data.fillna(method='ffill', axis=0)\n",
    "\n",
    "## Grouping the tokens to sentences\n",
    "data_group = data_fillna.groupby(['Sentence #'],\n",
    "                                 as_index=False)['Word', 'POS', 'Tag', \n",
    "                                                 'Word_idx', 'Tag_idx'].agg(lambda x: list(x))\n",
    "## Visualise data\n",
    "data_group.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E8gH5SIq5ISd",
    "outputId": "7ce4f890-a7d4-414a-af92-67ba65c50b3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47959, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_group.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LeZrGAPb95VF"
   },
   "source": [
    "**So we have a total of 47959 labelled sentences.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Model Training</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "zuajBlkChDRD"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "N_5Tks_JhUe2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow\n",
    "from tensorflow.keras import Sequential, Model, Input\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Activation  \n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "## Seed for reproducibility\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "tensorflow.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UrQae-r3hdRG",
    "outputId": "155931ab-a608-4178-dc1c-ec5376a6d7f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dim:  35179 \n",
      "output_dim:  64 \n",
      "input_length:  104 \n",
      "n_tags:  17\n"
     ]
    }
   ],
   "source": [
    "## Finding dimensions of embedding layer\n",
    "input_dim = len(list(set(data['Word'].to_list())))+1\n",
    "output_dim = 64\n",
    "input_length = max([len(s) for s in data_group['Word_idx'].tolist()])\n",
    "print('input_dim: ', input_dim, '\\noutput_dim: ', output_dim, '\\ninput_length: ', input_length, '\\nn_tags: ', n_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "PTPUaD1jhiA6"
   },
   "outputs": [],
   "source": [
    "def get_bilstm_lstm_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add Embedding layer\n",
    "    model.add(Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length))\n",
    "\n",
    "    # Add bidirectional LSTM\n",
    "    model.add(Bidirectional(LSTM(units=output_dim, return_sequences=True, dropout=0.2, recurrent_dropout=0.2), merge_mode = 'concat'))\n",
    "\n",
    "    # Add LSTM\n",
    "    model.add(LSTM(units=output_dim, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))\n",
    "\n",
    "    # Add timeDistributed Layer\n",
    "    model.add(TimeDistributed(Dense(n_tags, activation=\"relu\"))) \n",
    "\n",
    "    #Optimiser \n",
    "    # adam = k.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "15Q37KhXhrp-",
    "outputId": "878a23b8-52ec-481f-e8ca-e31c85012d25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 104, 64)           2251456   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 104, 128)          66048     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 104, 64)           49408     \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 104, 17)           1105      \n",
      "=================================================================\n",
      "Total params: 2,368,017\n",
      "Trainable params: 2,368,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bilstm_lstm = get_bilstm_lstm_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "QbV6jRqwhzqH",
    "outputId": "000ee064-89a5-42c7-aeb3-d481e6f55d3e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Visualizing the model\n",
    "plot_model(model_bilstm_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "IRMegPpXK23l"
   },
   "outputs": [],
   "source": [
    "## UTILITY FUNCTIONS\n",
    "\n",
    "def find_tags(arr3d):\n",
    "\n",
    "  idxs = []\n",
    "  for sent in arr3d:\n",
    "    for token in sent:\n",
    "      idxs.append(np.argmax(token))\n",
    "  return idxs\n",
    "\n",
    "def test_accuracy(pred_tags, orig_tags):\n",
    "  total, corr = len(pred_tags), 0\n",
    "  \n",
    "  for pred_tag, orig_tag in zip(pred_tags, orig_tags):\n",
    "    if pred_tag == orig_tag:\n",
    "      corr += 1\n",
    "  \n",
    "  return corr/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sc9F2NQbDBwH"
   },
   "source": [
    "## K-fold cross validation\n",
    "\n",
    "I am going to use a 10 fold cross-validation for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "id": "todp5leBjTRa",
    "outputId": "611161f2-ac51-4be0-896f-265211d16cfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape :-  (45000, 6)\n",
      "Test data shape :-  (2959, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Word_idx</th>\n",
       "      <th>Tag_idx</th>\n",
       "      <th>Fold_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31157</th>\n",
       "      <td>Sentence: 3804</td>\n",
       "      <td>[AN, OWL, ,, in, her, wisdom, ,, counseled, th...</td>\n",
       "      <td>[DT, NN, ,, IN, PRP$, NN, ,, VBD, DT, NNS, WDT...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[12859, 16427, 31857, 31013, 28818, 8291, 3185...</td>\n",
       "      <td>[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3883</th>\n",
       "      <td>Sentence: 13493</td>\n",
       "      <td>[The, prisoners, ', identities, were, not, imm...</td>\n",
       "      <td>[DT, NNS, POS, NNS, VBD, RB, RB, VBN, ,, CC, N...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, B-gpe, O, O, O,...</td>\n",
       "      <td>[9958, 6680, 10147, 12726, 25535, 18249, 18099...</td>\n",
       "      <td>[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 4, 10...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31140</th>\n",
       "      <td>Sentence: 38024</td>\n",
       "      <td>[The, bill, won, final, approval, in, the, Sta...</td>\n",
       "      <td>[DT, NN, VBD, JJ, NN, IN, DT, NN, NNP, IN, DT,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, B-geo, I-geo, O, O, O, O...</td>\n",
       "      <td>[9958, 2128, 32260, 10709, 32257, 31013, 23093...</td>\n",
       "      <td>[10, 10, 10, 10, 10, 10, 10, 14, 11, 10, 10, 1...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sentence #  ... Fold_id\n",
       "31157   Sentence: 3804  ...       0\n",
       "3883   Sentence: 13493  ...       1\n",
       "31140  Sentence: 38024  ...       2\n",
       "\n",
       "[3 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Randomly shuffling the datapoints\n",
    "data_group = data_group.sample(frac=1)\n",
    "\n",
    "## Splitting up data into train & test set\n",
    "train_data_group = data_group[:45000]\n",
    "test_data_group = data_group[45000:]\n",
    "print(\"Train data shape :- \",train_data_group.shape)\n",
    "print(\"Test data shape :- \",test_data_group.shape)\n",
    "\n",
    "kfold = 10\n",
    "fold_idxs = [(i % kfold) for i in range(train_data_group.shape[0])]\n",
    "\n",
    "train_data_group[\"Fold_id\"] = fold_idxs\n",
    "train_data_group.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EYjpXlVpDBZU",
    "outputId": "087903d6-7136-4aab-d8d2-644bf540bc67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen = max([len(s) for s in train_data_group['Word_idx'].tolist()])\n",
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Yz8k_x1enrKt"
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "9pUuKFZcl_yP"
   },
   "outputs": [],
   "source": [
    "def get_pad_tokens_tags(tokens, tags, maxlen, n_token, n_tags):\n",
    "  \"\"\"Returns padded tokens & tags\"\"\"\n",
    "\n",
    "  ## Padding tokens\n",
    "  pad_tokens = pad_sequences(tokens, maxlen=maxlen, dtype='int32', padding='post', value=n_token-1)\n",
    "  \n",
    "  ## Padding tags & one hot encoding them\n",
    "  pad_tags = pad_sequences(tags, maxlen=maxlen, dtype='int32', padding='post', value=tag2idx[\"O\"])\n",
    "  pad_tags = [to_categorical(i, num_classes=n_tags) for i in pad_tags] \n",
    "\n",
    "  return (pad_tokens, pad_tags)\n",
    "\n",
    "def crossval(train_data_group, test_data_group, maxlen, n_token, n_tags, kfold):\n",
    "    \"\"\"Returns the history & test-set accuracy for all folds.\"\"\"\n",
    "    \n",
    "    hist_ls, test_acc_ls = [], []\n",
    "    batch_size = 1024\n",
    "    num_epochs = 5\n",
    "  \n",
    "    test_tokens = test_data_group['Word_idx'].tolist()\n",
    "    test_tags = test_data_group['Tag_idx'].tolist()    \n",
    "    \n",
    "    ## Get padded tokens & tags for testing model on unseen data\n",
    "    test_pad_tokens, test_pad_tags = get_pad_tokens_tags(test_tokens, test_tags, maxlen, n_token, n_tags)   \n",
    "\n",
    "    for i in range(kfold):\n",
    "\n",
    "      train_data_grp = train_data_group[train_data_group[\"Fold_id\"] != i]\n",
    "      val_data_grp = train_data_group[train_data_group[\"Fold_id\"] == i]\n",
    "\n",
    "      ## Tokens - (X var) , Tags - (Y var)   \n",
    "      train_tokens = train_data_grp['Word_idx'].tolist()\n",
    "      train_tags = train_data_grp['Tag_idx'].tolist()\n",
    "      val_tokens = val_data_grp['Word_idx'].tolist()\n",
    "      val_tags = val_data_grp['Tag_idx'].tolist()\n",
    "\n",
    "      ## Get padded tokens & tags\n",
    "      train_pad_tokens, train_pad_tags = get_pad_tokens_tags(train_tokens, train_tags, maxlen, n_token, n_tags)      \n",
    "      val_pad_tokens, val_pad_tags = get_pad_tokens_tags(val_tokens, val_tags, maxlen, n_token, n_tags)\n",
    "\n",
    "      ## Getting new model\n",
    "      model = get_bilstm_lstm_model()\n",
    "\n",
    "      # Saving the best model only\n",
    "      filepath=\"ner-bi-lstm-fold{}.hdf5\".format(i)\n",
    "      checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "      callbacks_list = [checkpoint]\n",
    "\n",
    "      print(\"Training started with validation fold-{}\".format(i))\n",
    "      st = time.time()\n",
    "      hist = model.fit(train_pad_tokens, \n",
    "                       np.array(train_pad_tags), \n",
    "                       batch_size=batch_size, \n",
    "                       verbose=0, \n",
    "                       epochs=num_epochs, \n",
    "                       validation_data = (val_pad_tokens, np.array(val_pad_tags)), \n",
    "                       callbacks=callbacks_list) \n",
    "      en = time.time()\n",
    "      print(\"Fold-{} training time = {} mins\".format(i,(en-st)/60)) \n",
    "      hist_ls.append(hist)    \n",
    "\n",
    "      pred = model.predict(test_pad_tokens)\n",
    "      pred_tags = find_tags(pred)\n",
    "      orig_tags = find_tags(np.array(test_pad_tags))\n",
    "      \n",
    "      test_acc = test_accuracy(pred_tags, orig_tags)\n",
    "      test_acc_ls.append(test_acc)\n",
    "      print(\"Fold {} complete. Test set accuracy - {}\".format(i, test_acc))\n",
    "      print(\"*\"*100+\"\\n\\n\")\n",
    "\n",
    "    \n",
    "    return (hist_ls, test_acc_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gX97PEqYnQ3F",
    "outputId": "386272be-d29f-40f3-fb7e-ecb3d52508d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Training started with validation fold-0\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.96799, saving model to ner-bi-lstm-fold0.hdf5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.96799\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.96799\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.96799\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.96799\n",
      "Fold-0 training time = 7.179142208894094 mins\n",
      "Fold 0 complete. Test set accuracy - 0.9680992799022539\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Training started with validation fold-1\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.96757, saving model to ner-bi-lstm-fold1.hdf5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.96757\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.96757\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.96757 to 0.96758, saving model to ner-bi-lstm-fold1.hdf5\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.96758 to 0.96768, saving model to ner-bi-lstm-fold1.hdf5\n",
      "Fold-1 training time = 7.590966049830119 mins\n",
      "Fold 1 complete. Test set accuracy - 0.9681967660592196\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Training started with validation fold-2\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.96805, saving model to ner-bi-lstm-fold2.hdf5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.96805\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.96805\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.96805\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.96805\n",
      "Fold-2 training time = 7.508155488967896 mins\n",
      "Fold 2 complete. Test set accuracy - 0.9680927808251228\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Training started with validation fold-3\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.96813, saving model to ner-bi-lstm-fold3.hdf5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.96813\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.96813\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.96813\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.96813\n",
      "Fold-3 training time = 7.008260492483775 mins\n",
      "Fold 3 complete. Test set accuracy - 0.9680927808251228\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Training started with validation fold-4\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.96853, saving model to ner-bi-lstm-fold4.hdf5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.96853\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.96853\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.96853 to 0.96853, saving model to ner-bi-lstm-fold4.hdf5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.96853\n",
      "Fold-4 training time = 7.503317598501841 mins\n",
      "Fold 4 complete. Test set accuracy - 0.9680960303636884\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Training started with validation fold-5\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.96747, saving model to ner-bi-lstm-fold5.hdf5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.96747\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.96747 to 0.96748, saving model to ner-bi-lstm-fold5.hdf5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.96748\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.96748\n",
      "Fold-5 training time = 7.077467656135559 mins\n",
      "Fold 5 complete. Test set accuracy - 0.9680927808251228\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Training started with validation fold-6\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.96825, saving model to ner-bi-lstm-fold6.hdf5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.96825\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.96825 to 0.96825, saving model to ner-bi-lstm-fold6.hdf5\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.96825 to 0.96826, saving model to ner-bi-lstm-fold6.hdf5\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.96826 to 0.96830, saving model to ner-bi-lstm-fold6.hdf5\n",
      "Fold-6 training time = 7.097572767734528 mins\n",
      "Fold 6 complete. Test set accuracy - 0.9681317752879092\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Training started with validation fold-7\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.96721, saving model to ner-bi-lstm-fold7.hdf5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.96721\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.96721\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.96721 to 0.96721, saving model to ner-bi-lstm-fold7.hdf5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.96721\n",
      "Fold-7 training time = 7.033896370728811 mins\n",
      "Fold 7 complete. Test set accuracy - 0.9680927808251228\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Training started with validation fold-8\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.96717, saving model to ner-bi-lstm-fold8.hdf5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.96717\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.96717\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.96717\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.96717\n",
      "Fold-8 training time = 7.49548598130544 mins\n",
      "Fold 8 complete. Test set accuracy - 0.9680927808251228\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Training started with validation fold-9\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.96732, saving model to ner-bi-lstm-fold9.hdf5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.96732\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.96732 to 0.96733, saving model to ner-bi-lstm-fold9.hdf5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.96733\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.96733\n",
      "Fold-9 training time = 7.497020065784454 mins\n",
      "Fold 9 complete. Test set accuracy - 0.9680960303636884\n",
      "****************************************************************************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hist_ls, test_acc_ls = crossval(train_data_group, test_data_group, maxlen, n_token, n_tags, kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Edw03CLNiGNS",
    "outputId": "515c2cb1-c9a9-4f6d-cda4-d0ed8e0d9c5e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9680992799022539,\n",
       " 0.9681967660592196,\n",
       " 0.9680927808251228,\n",
       " 0.9680927808251228,\n",
       " 0.9680960303636884,\n",
       " 0.9680927808251228,\n",
       " 0.9681317752879092,\n",
       " 0.9680927808251228,\n",
       " 0.9680927808251228,\n",
       " 0.9680960303636884]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TEST SET ACCURACIES\n",
    "test_acc_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3w0mvFDHCnS7"
   },
   "source": [
    "**BEST TEST SET ACCURACY ACHIEVED IS 96.82%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Custom_NER_using_Keras.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
